{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating single word features\n",
      "accuracy: 0.728\n",
      "pos precision: 0.651595744681\n",
      "pos recall: 0.98\n",
      "neg precision: 0.959677419355\n",
      "neg recall: 0.476\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FreqDist' object has no attribute 'inc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f0ba11565f5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmovie_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mword_fd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mlabel_word_fd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FreqDist' object has no attribute 'inc'"
     ]
    }
   ],
   "source": [
    "import collections, itertools\n",
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "\n",
    "def evaluate_classifier(featx):\n",
    "\tnegids = movie_reviews.fileids('neg')\n",
    "\tposids = movie_reviews.fileids('pos')\n",
    "\n",
    "\tnegfeats = [(featx(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "\tposfeats = [(featx(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "\tnegcutoff = len(negfeats)*3/4\n",
    "\tposcutoff = len(posfeats)*3/4\n",
    "\n",
    "\ttrainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "\ttestfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "\n",
    "\tclassifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\trefsets = collections.defaultdict(set)\n",
    "\ttestsets = collections.defaultdict(set)\n",
    "\n",
    "\tfor i, (feats, label) in enumerate(testfeats):\n",
    "\t\t\trefsets[label].add(i)\n",
    "\t\t\tobserved = classifier.classify(feats)\n",
    "\t\t\ttestsets[observed].add(i)\n",
    "\n",
    "\tprint 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
    "\tprint 'pos precision:', nltk.metrics.precision(refsets['pos'], testsets['pos'])\n",
    "\tprint 'pos recall:', nltk.metrics.recall(refsets['pos'], testsets['pos'])\n",
    "\tprint 'neg precision:', nltk.metrics.precision(refsets['neg'], testsets['neg'])\n",
    "\tprint 'neg recall:', nltk.metrics.recall(refsets['neg'], testsets['neg'])\n",
    "\tclassifier.show_most_informative_features()\n",
    "\n",
    "def word_feats(words):\n",
    "\treturn dict([(word, True) for word in words])\n",
    "\n",
    "print 'evaluating single word features'\n",
    "evaluate_classifier(word_feats)\n",
    "\n",
    "word_fd = FreqDist()\n",
    "label_word_fd = ConditionalFreqDist()\n",
    "\n",
    "for word in movie_reviews.words(categories=['pos']):\n",
    "\tword_fd.inc(word.lower())\n",
    "\tlabel_word_fd['pos'].inc(word.lower())\n",
    "\n",
    "for word in movie_reviews.words(categories=['neg']):\n",
    "\tword_fd.inc(word.lower())\n",
    "\tlabel_word_fd['neg'].inc(word.lower())\n",
    "\n",
    "# n_ii = label_word_fd[label][word]\n",
    "# n_ix = word_fd[word]\n",
    "# n_xi = label_word_fd[label].N()\n",
    "# n_xx = label_word_fd.N()\n",
    "\n",
    "pos_word_count = label_word_fd['pos'].N()\n",
    "neg_word_count = label_word_fd['neg'].N()\n",
    "total_word_count = pos_word_count + neg_word_count\n",
    "\n",
    "word_scores = {}\n",
    "\n",
    "for word, freq in word_fd.iteritems():\n",
    "\tpos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "\t\t(freq, pos_word_count), total_word_count)\n",
    "\tneg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "\t\t(freq, neg_word_count), total_word_count)\n",
    "\tword_scores[word] = pos_score + neg_score\n",
    "\n",
    "best = sorted(word_scores.iteritems(), key=lambda (w,s): s, reverse=True)[:10000]\n",
    "bestwords = set([w for w, s in best])\n",
    "\n",
    "def best_word_feats(words):\n",
    "\treturn dict([(word, True) for word in words if word in bestwords])\n",
    "\n",
    "print 'evaluating best word features'\n",
    "evaluate_classifier(best_word_feats)\n",
    "\n",
    "def best_bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "\tbigram_finder = BigramCollocationFinder.from_words(words)\n",
    "\tbigrams = bigram_finder.nbest(score_fn, n)\n",
    "\td = dict([(bigram, True) for bigram in bigrams])\n",
    "\td.update(best_word_feats(words))\n",
    "\treturn d\n",
    "\n",
    "print 'evaluating best words + bigram chi_sq word features'\n",
    "evaluate_classifier(best_bigram_word_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CategorizedPlaintextCorpusReader in u'C:\\\\Users\\\\Wotashu\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'The', u'DT'),\n",
       " (u'titular', u'JJ'),\n",
       " (u'threat', u'NN'),\n",
       " (u'of', u'IN'),\n",
       " (u'The', u'DT'),\n",
       " (u'Blob', u'NNP'),\n",
       " (u'has', u'VBZ'),\n",
       " (u'always', u'RB'),\n",
       " (u'struck', u'VBD'),\n",
       " (u'me', u'PRP'),\n",
       " (u'as', u'IN'),\n",
       " (u'the', u'DT'),\n",
       " (u'ultimate', u'JJ'),\n",
       " (u'movie', u'NN'),\n",
       " (u'monster', u'NN'),\n",
       " (u'an', u'DT'),\n",
       " (u'insatiably', u'RB'),\n",
       " (u'hungry', u'JJ'),\n",
       " (u'amoeba-like', u'JJ'),\n",
       " (u'mass', u'NN'),\n",
       " (u'able', u'JJ'),\n",
       " (u'to', u'TO'),\n",
       " (u'penetrate', u'VB'),\n",
       " (u'virtually', u'RB'),\n",
       " (u'any', u'DT'),\n",
       " (u'safeguard', u'VB'),\n",
       " (u'capable', u'JJ'),\n",
       " (u'of--as', u'JJ'),\n",
       " (u'a', u'DT'),\n",
       " (u'doomed', u'VBN'),\n",
       " (u'doctor', u'NN'),\n",
       " (u'chillingly', u'RB'),\n",
       " (u'describes', u'VBZ'),\n",
       " (u'it', u'PRP'),\n",
       " (u'assimilating', u'VBG'),\n",
       " (u'flesh', u'NN'),\n",
       " (u'on', u'IN'),\n",
       " (u'contact', u'NN'),\n",
       " (u'Snide', u'NNP'),\n",
       " (u'comparisons', u'NNS'),\n",
       " (u'to', u'TO'),\n",
       " (u'gelatin', u'NN'),\n",
       " (u'be', u'VB'),\n",
       " (u'damned', u'JJ'),\n",
       " (u'it', u'PRP'),\n",
       " (u\"'\", u'POS'),\n",
       " (u's', u'PRP'),\n",
       " (u'a', u'DT'),\n",
       " (u'concept', u'NN'),\n",
       " (u'with', u'IN'),\n",
       " (u'the', u'DT'),\n",
       " (u'most', u'RBS'),\n",
       " (u'devastating', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'potential', u'JJ'),\n",
       " (u'consequences', u'NNS'),\n",
       " (u'not', u'RB'),\n",
       " (u'unlike', u'IN'),\n",
       " (u'the', u'DT'),\n",
       " (u'grey', u'JJ'),\n",
       " (u'goo', u'NN'),\n",
       " (u'scenario', u'NN'),\n",
       " (u'proposed', u'VBN'),\n",
       " (u'by', u'IN'),\n",
       " (u'technological', u'JJ'),\n",
       " (u'theorists', u'NNS'),\n",
       " (u'fearful', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'artificial', u'JJ'),\n",
       " (u'intelligence', u'NN'),\n",
       " (u'run', u'VB'),\n",
       " (u'rampant', u'JJ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'titular threat', 'blob', u'ultimate movie monster', u'amoeba-like mass', 'snide', u'potential consequences', u'grey goo scenario', u'technological theorists fearful', u'artificial intelligence run rampant'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n",
      "-0.341666666667\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
